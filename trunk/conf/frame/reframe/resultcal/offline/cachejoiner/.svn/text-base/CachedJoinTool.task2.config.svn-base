<config>
	<composite name="personaltailor">
		<leaf name="cachedjoin">
			<!--任务类，该类用于带cache的表连接，将小表作为cache与大表进行内连接-->
			<class>com.eb.bi.rs.frame.recframe.resultcal.offline.cachejoiner.CachedJoinTool</class>
			<configuration>
				<!--输入文件的字段分割符正则表达式，不配置则默认为"\|"-->
				<conf.input.delimiter>\|</conf.input.delimiter>
				<!--cache文件的字段分割符正则表达式，不配置则默认为"\|"-->
				<conf.cache.delimiter>\|</conf.cache.delimiter>
				<!--输出文件的字段分割符，不配置则默认为"|"-->
				<conf.output.delimiter>|</conf.output.delimiter>
				<!--输出时，输入文件中的字段是否放在cache文件中的字段前面，不配置则默认为true-->
				<conf.output.input.first>false</conf.output.input.first>

				<!--cache文件中的key在字段中的索引值-->
				<conf.cache.key.index>1</conf.cache.key.index>
				<!--输入文件中的key在字段中的索引值-->
				<conf.input.key.index>1</conf.input.key.index>
				<!--输入路径-->
				<conf.input.path>/home/idox/ynn/input.txt</conf.input.path>
				<!--输出目录-->
				<conf.output.path>/home/idox/ynn/output</conf.output.path>
				<!--cache文件的路径-->
				<conf.cache.path>/home/idox/ynn/cache.txt</conf.cache.path>
				
				<!--输出时，输入文件中的字段与cache文件中的字段顺序，下标从0开始-->
				<conf.output.order>f0,f2,c0,c2,f3</conf.output.order>
				<!--conf.output.order分割符，不配置则默认为","-->
				<conf.output.order.delimiter>,</conf.output.order.delimiter>
				<!--conf.output.order第一个文件字段名-->
				<conf.output.file1.field>f</conf.output.file1.field>
				<!--conf.output.order第二个文件字段名-->
				<conf.output.file2.field>c</conf.output.file2.field>
				
				<!--输入格式，默认是TextInputFormat，如果想要配置SequenceFileInputFormat，填写org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat-->
				<conf.inputformat.class>org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat</conf.inputformat.class>
				<!--输出格式，默认是TextOutputFormat，如果想要配置SequenceFileOutputFormat，填写org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat-->
				<conf.outputformat.class>org.apache.hadoop.mapreduce.lib.output.TextOutputFormat</conf.outputformat.class>
				<!--输出时是否压缩，可选项是true，false-->
				<conf.output.compress>false</conf.output.compress>
				<!--如果压缩，压缩格式，如果要配置lzo，填写com.hadoop.compression.lzo.LzoCodec-->
				<conf.output.compression.codec>org.apache.hadoop.io.compress.CompressionCodec</conf.output.compression.codec>
				<!--sequenceFile是记录压缩，还是块压缩，可选项是BLOCK,RECORD-->
				<conf.output.compression.type>BLOCK</conf.output.compression.type>			
			</configuration>
		</leaf>
	</composite>
</config>
